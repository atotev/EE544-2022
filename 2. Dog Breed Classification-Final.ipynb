{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from os import environ\n",
    "import os\n",
    "import random as random\n",
    "from tensorflow.keras.preprocessing import image as imgproc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to make runs more reproducible\n",
    "seed_value=20212042\n",
    "print(\"Using random seed: %d\" % seed_value)\n",
    "environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value) # tensorflow 2.x\n",
    "\n",
    "print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './imagewoof2-320'\n",
    "TRAIN_DIR = path.join(DATA_DIR, 'train')\n",
    "VALIDATION_DIR = path.join(DATA_DIR, 'validation') # a split off 'train' used as validation set during NN training\n",
    "TEST_DIR = path.join(DATA_DIR, 'val') # the original Imagenette test dir\n",
    "MODELS_DIR = path.join('./models')\n",
    "LABELS_FILE = path.join(DATA_DIR, 'noisy_imagewoof.csv')\n",
    "BREEDS = { # mappings from: https://image-net.org/challenges/LSVRC/2014/browse-synsets.php\n",
    "    'n02086240': 'Shih-Tzu',\n",
    "    'n02087394': 'Rhodesian ridgeback',\n",
    "    'n02088364': 'beagle',\n",
    "    'n02089973': 'English foxhound',\n",
    "    'n02093754': 'Border terrier'\n",
    "}\n",
    "CLASSES = ['n02086240', 'n02087394', 'n02088364', 'n02089973', 'n02093754'] # BREEDS.keys()\n",
    "IMG_SIZE = (299, 299)\n",
    "COLOUR_SCALE = 1/255.\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_model_history(history):\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    \n",
    "    # Categorical Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['categorical_accuracy'])\n",
    "    plt.plot(history.history['val_categorical_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('categorical_accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def load_random_image(filepath):\n",
    "    img_file = random.choice(os.listdir(filepath))\n",
    "    img = imgproc.load_img(path.join(filepath, img_file))\n",
    "    img = img.resize(IMG_SIZE)\n",
    "    img_array = imgproc.img_to_array(img)\n",
    "    return img_array * COLOUR_SCALE\n",
    "\n",
    "# Data generation flow from train/validation directory\n",
    "def create_flow(datagen, path, batch_size):\n",
    "    # TODO document choices\n",
    "    return datagen.flow_from_directory(\n",
    "        path,\n",
    "        target_size=IMG_SIZE,\n",
    "        classes=CLASSES,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "def evaluate_model(model_file, data_path=TEST_DIR):\n",
    "    model = models.load_model(model_file)\n",
    "    test_flow = create_flow(ImageDataGenerator(rescale=COLOUR_SCALE), data_path, 1)\n",
    "\n",
    "    loss_accuracy = model.evaluate(test_flow, steps=test_flow.samples, verbose=False)\n",
    "    print('Evaluating against data in %s: Loss=%.2f, Accuracy=%.2f%%' % (data_path, loss_accuracy[0], loss_accuracy[1] * 100.))\n",
    "    \n",
    "    test_flow.reset()\n",
    "    y_true = []\n",
    "    for i in range(test_flow.samples):\n",
    "        _, y = test_flow.next()\n",
    "        y_true.append(np.argmax(y, axis=1))\n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    test_flow.reset()\n",
    "    y_pred = model.predict(test_flow, steps=test_flow.samples, verbose=False)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASSES)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make train/validation split and organize directory structure accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.isdir(VALIDATION_DIR):\n",
    "    ground_truth = pd.read_csv(LABELS_FILE)\n",
    "    ground_truth = ground_truth[ground_truth['noisy_labels_0'].isin(CLASSES)]\n",
    "    test_df = ground_truth[ground_truth['is_valid']==True]\n",
    "    imagenette_train = ground_truth[ground_truth['is_valid']==False]\n",
    "    train_df, val_df = train_test_split(imagenette_train, test_size=0.2) # the dataset is balanced\n",
    "    val_df = val_df.rename(columns={'path': 'orig_path'})\n",
    "    val_df['path'] = val_df['orig_path'].str.replace('train/', 'validation/')\n",
    "    val_df.apply(lambda v: os.renames(path.join(DATA_DIR, v['orig_path']), path.join(DATA_DIR, v['path'])), axis=1)\n",
    "    del val_df['orig_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train InceptionV3-based CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ImageDataGenerator(rescale=COLOUR_SCALE)\n",
    "model_file = path.join(MODELS_DIR, 'imagewoof', 'inceptionv3_based.h5')\n",
    "if not path.isfile(model_file):\n",
    "    os.makedirs(path.dirname(model_file), exist_ok=True)\n",
    "    \n",
    "    # Create InceptionV3 model\n",
    "    inceptionv3 = keras.applications.InceptionV3(weights='imagenet', include_top=False)\n",
    "    inceptionv3.trainable = False\n",
    "\n",
    "    # Add new top layers for classification\n",
    "    inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
    "    x = inceptionv3(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "    finetuned_model = keras.Model(inputs=inputs, outputs=output)\n",
    "    finetuned_model.compile(\n",
    "        optimizers.RMSprop(lr=1e-3),\n",
    "        'categorical_crossentropy',\n",
    "        metrics=[metrics.CategoricalAccuracy()]\n",
    "    )\n",
    "    finetuned_model.summary()\n",
    "\n",
    "    # Train model\n",
    "    epochs_count = 10\n",
    "    train_gen = ImageDataGenerator( # TODO document choices\n",
    "        rescale=COLOUR_SCALE,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    train_flow = create_flow(train_gen, TRAIN_DIR, BATCH_SIZE)\n",
    "    val_flow = create_flow(ImageDataGenerator(rescale=COLOUR_SCALE), VALIDATION_DIR, BATCH_SIZE)\n",
    "    save_best_cb = callbacks.ModelCheckpoint(filepath=model_file,\n",
    "                                             monitor='val_loss', mode='min', save_best_only=True,\n",
    "                                             verbose=False) # set to True to see best model's epoch\n",
    "    history = finetuned_model.fit(train_flow, steps_per_epoch=train_flow.samples // BATCH_SIZE,\n",
    "                       validation_data=val_flow, validation_steps=val_flow.samples // BATCH_SIZE,\n",
    "                       epochs=epochs_count,\n",
    "                       callbacks=[save_best_cb],\n",
    "                       verbose=False)\n",
    "    plot_model_history(history)\n",
    "    evaluate_model(model_file)\n",
    "    \n",
    "    # Load best weights\n",
    "    finetuned_model.load_weights(model_file)\n",
    "    \n",
    "    # Freeze all layers up to the top two inception blocks\n",
    "    inceptionv3.trainable = True\n",
    "    first_trainable_layer = 250\n",
    "    for layer in inceptionv3.layers[:first_trainable_layer]:\n",
    "        layer.trainable = False\n",
    "    for layer in inceptionv3.layers[first_trainable_layer:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # Fine tune model\n",
    "    epochs_count = 50\n",
    "    finetuned_model.compile(\n",
    "        optimizers.RMSprop(lr=1e-5),\n",
    "        'categorical_crossentropy',\n",
    "        metrics=[metrics.CategoricalAccuracy()]\n",
    "    )\n",
    "    finetuned_model.summary()\n",
    "    history = finetuned_model.fit(train_flow, steps_per_epoch=train_flow.samples // BATCH_SIZE,\n",
    "                       validation_data=val_flow, validation_steps=val_flow.samples // BATCH_SIZE,\n",
    "                       epochs=epochs_count,\n",
    "                       callbacks=[save_best_cb],\n",
    "                       verbose=False)\n",
    "    plot_model_history(history)\n",
    "\n",
    "# Evaluate against test dataset\n",
    "evaluate_model(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate against unseen images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model_file, './imagewoof2-in_the_wild')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
